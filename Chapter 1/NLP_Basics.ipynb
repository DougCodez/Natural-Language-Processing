{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "id": "YTyNKCWB9EGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2ae3b2-be78-4ec4-b5f7-9697d52477cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.5)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-28 01:16:30.770345: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-28 01:16:33.527188: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-28 01:16:33.527360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-28 01:16:33.527390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-28 01:16:38.580835: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.1/en_core_web_md-3.4.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-md==3.4.1) (3.4.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.22.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.12)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.25.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.10.5)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (6.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.1)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.4.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SZNotp5u2mze"
      },
      "outputs": [],
      "source": [
        "class Category : \n",
        "  NUMBERS = \"NUMBERS\"\n",
        "  LETTERS = \"LETTERS\"\n",
        "\n",
        "trainX = ['my favorite number is 1.', 'the number 23 comes after 22', 'the letter z comes after y', 'the letter a comes before b']\n",
        "trainY = [Category.NUMBERS, Category.NUMBERS, Category.LETTERS, Category.LETTERS]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(binary=True)\n",
        "\n",
        "#Finds the unique words to make these vectors & transforming the utterances we passed in based on that vector we just fitted\n",
        "tainXVectors = vectorizer.fit_transform(trainX)\n",
        "\n",
        "print(vectorizer.get_feature_names())\n",
        "\n",
        "print(tainXVectors.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoRiBOP334oR",
        "outputId": "ee12e14c-96eb-44c5-c4eb-6712bf05a52a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['22', '23', 'after', 'before', 'comes', 'favorite', 'is', 'letter', 'my', 'number', 'the']\n",
            "[[0 0 0 0 0 1 1 0 1 1 0]\n",
            " [1 1 1 0 1 0 0 0 0 1 1]\n",
            " [0 0 1 0 1 0 0 1 0 0 1]\n",
            " [0 0 0 1 1 0 0 1 0 0 1]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model to classify whether this is a numbers category or letters category\n",
        "from sklearn import svm\n",
        "\n",
        "clfSVM = svm.SVC(kernel='linear')\n",
        "clfSVM.fit(tainXVectors, trainY)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ3IGx8N56hl",
        "outputId": "6ece9203-604f-4056-bf98-e83962d90bed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a dummy to predict its category.\n",
        "dummyX = vectorizer.transform(['b comes after the letter a'])\n",
        "clfSVM.predict(dummyX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njD3Kzi86Bbe",
        "outputId": "d8ec82e7-4b2b-4e1b-dc2e-902f0a81c114"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['LETTERS'], dtype='<U7')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Vectors "
      ],
      "metadata": {
        "id": "H9vn-_5U847r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy \n",
        "\n",
        "nlp = spacy.load('en_core_web_md')"
      ],
      "metadata": {
        "id": "HrcpbWNY88Sw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2025fba-a85c-453a-e09a-7cfd031405cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l84wVoUo-Pbv",
        "outputId": "f8955fa9-b39c-4da8-9db1-17074998fbef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my favorite number is 1.',\n",
              " 'the number 23 comes after 22',\n",
              " 'the letter z comes after y',\n",
              " 'the letter a comes before b']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word vector representation of our sentences\n",
        "docs = [nlp(text) for text in trainX]\n",
        "trainXWV = [x.vector for x in docs]"
      ],
      "metadata": {
        "id": "7WjENXZS9qVz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfSVMWordVector = svm.SVC(kernel='linear')\n",
        "clfSVMWordVector.fit(trainXWV, trainY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B27uw3MS-d3L",
        "outputId": "43d3c22c-4dc3-491c-f9c4-91b493a644d2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummyX = ['i sent an email']\n",
        "dummyDocs = [nlp(text) for text in dummyX]\n",
        "dummyXWordVector = [x.vector for x in dummyDocs];\n",
        "clfSVMWordVector.predict(dummyXWordVector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SdoQjUx-9K7",
        "outputId": "54990e60-07a0-4f18-acc6-bbd5b3bb1ebd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['LETTERS'], dtype='<U7')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reg Expression"
      ],
      "metadata": {
        "id": "iNJhQAitFZ0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "regExp = re.compile('^ab[^\\s]*cd$')\n",
        "\n",
        "phrases = [\"abcd\", \"cdba\", \"dcba\", \"ab cd\", \"abxxxxxxcd\", \"xxx\"]\n",
        "matches = []\n",
        "for phrase in phrases:\n",
        "  if re.match(regExp, phrase):\n",
        "    matches.append(phrase)\n",
        "print(matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN_E4dXAEtnv",
        "outputId": "df27fcb9-b03b-4217-8ce8-f541ad450896"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abcd', 'abxxxxxxcd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming/Lemmatization\n",
        "\n",
        "Stemming lowers the inflection in words to their root forms.\n",
        "\n",
        "Lemmatizing means the process of reducing the different forms of a specific word to one single form"
      ],
      "metadata": {
        "id": "t8rslUztFjkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPYP4El4FhPA",
        "outputId": "37bad0af-5ca9-412f-e248-4b271ab8a691"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "dummyPhrase = \"letter a comes before b\"\n",
        "words = word_tokenize(dummyPhrase)\n",
        "print(words)\n",
        "stemmed_words = [stemmer.stem(word) for word in words] \n",
        "\" \".join(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "1PaMWveTF5yw",
        "outputId": "80ad941b-2c8d-4c2d-d1ed-deea77027267"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['letter', 'a', 'comes', 'before', 'b']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'letter a come befor b'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "#This download is required in order to use the lemmatizer package\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq8yyVz-H4uH",
        "outputId": "6dc76ecb-68a9-40d8-89fa-2dc179550438"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "dummyPhrase = \"the letter a comes before b\"\n",
        "words = word_tokenize(dummyPhrase)\n",
        "\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\" \".join(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Dkwi_EO5G4Tg",
        "outputId": "0cd29931-eb6b-47de-c4a2-20c380547f66"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the letter a come before b'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stopwords\n",
        "Stop words are the words in a stop list which are filtered out before or after processing of natural language data because they are insignificant."
      ],
      "metadata": {
        "id": "tmYf5WF7JUvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "dummyPhrase = 'I have to go to work today, but before I do that, I have to drop off a package at the post office.'\n",
        "words = word_tokenize(dummyPhrase)\n",
        "strippedPhrase = [word for word in words if word not in stop_words]\n",
        "print(words)\n",
        "\" \".join(strippedPhrase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "W3bnIB8tJbyJ",
        "outputId": "fb43b286-76eb-4946-9226-4a10fb86d236"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'have', 'to', 'go', 'to', 'work', 'today', ',', 'but', 'before', 'I', 'do', 'that', ',', 'I', 'have', 'to', 'drop', 'off', 'a', 'package', 'at', 'the', 'post', 'office', '.']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I go work today , I , I drop package post office .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a total of 179 stop words in the natural language tool kit stop words module."
      ],
      "metadata": {
        "id": "FNEWJ2f177el"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')\n",
        "print(len(stop_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DzVLebb7v5I",
        "outputId": "6e0a3362-e2d1-401f-eaba-85b8f9875be0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Various Techniques (Spell Correction, Sentiment, Part of Speech)\n",
        "Using Textblob will try its best to show the tag that best belongs to the word. For example, whether it is a noun, verb, adjective, etc"
      ],
      "metadata": {
        "id": "W7lfJW-4MRVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJccAldjP5lo",
        "outputId": "af7390dd-d9ee-4cd4-e8b4-c8359d248b11"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textblob"
      ],
      "metadata": {
        "id": "WVGWxZbWPxFX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "dummyPhrase = input('Type a phrase of some sort: ')\n",
        "\n",
        "textblobPhrase = TextBlob(dummyPhrase)\n",
        "textblobPhrase.correct()\n",
        "textblobPhrase.tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slYeLTzfMPza",
        "outputId": "4e091043-05ba-45c2-e9dd-52233960a5ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type a phrase of some sort: This is a dummy phrase I am typing\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'DT'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('dummy', 'JJ'),\n",
              " ('phrase', 'NN'),\n",
              " ('I', 'PRP'),\n",
              " ('am', 'VBP'),\n",
              " ('typing', 'VBG')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textblobPhrase.sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6s1T5EARZ_R",
        "outputId": "d7e86038-d0b1-4334-8a16-894315cdaeca"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.0, subjectivity=0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks\n",
        "https://imgpile.com/i/dShyXj\n",
        "\n",
        "Longer dependencies do not always perform well"
      ],
      "metadata": {
        "id": "kuky0FnXR085"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention\n",
        "\n",
        "What token are particularly relevant and should be attended too?\n",
        "\n",
        "The NN learns to ask questions about phrases it sees, to learn how tokens relate."
      ],
      "metadata": {
        "id": "GVMRkZ89VSeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Architecture\n",
        "\n"
      ],
      "metadata": {
        "id": "gotu_dOxWNPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy-transformers\n",
        "!python3 -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpBehvxLR0JP",
        "outputId": "4c440eb1-6ea2-4576-9bfd-994ec49d6322"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy-transformers\n",
            "  Downloading spacy_transformers-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-alignments<1.0.0,>=0.7.2\n",
            "  Downloading spacy_alignments-0.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers) (2.4.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers) (1.13.1+cu116)\n",
            "Collecting spacy<4.0.0,>=3.5.0\n",
            "  Downloading spacy-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers<4.27.0,>=3.4.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (1.10.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (4.64.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (2.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (23.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (2.25.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (1.0.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (1.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (2.11.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (6.3.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (57.4.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8.0->spacy-transformers) (4.5.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers) (6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<4.0.0,>=3.5.0->spacy-transformers) (2.0.1)\n",
            "Installing collected packages: tokenizers, spacy-alignments, huggingface-hub, transformers, spacy, spacy-transformers\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.4\n",
            "    Uninstalling spacy-3.4.4:\n",
            "      Successfully uninstalled spacy-3.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.5.0 which is incompatible.\n",
            "en-core-web-md 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.12.1 spacy-3.5.0 spacy-alignments-0.9.0 spacy-transformers-1.2.2 tokenizers-0.13.2 transformers-4.26.1\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-28 01:18:02.508002: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-28 01:18:02.508132: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-28 01:18:02.508158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-28 01:18:07.666134: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-trf==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.5.0/en_core_web_trf-3.5.0-py3-none-any.whl (460.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.3/460.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-transformers<1.3.0,>=1.2.0.dev0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-trf==3.5.0) (1.2.2)\n",
            "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-trf==3.5.0) (3.5.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.4.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (4.64.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.25.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (57.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (8.1.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (1.10.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (1.13.1+cu116)\n",
            "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: transformers<4.27.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (4.26.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (4.0.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (0.12.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-trf\n",
            "Successfully installed en-core-web-trf-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "doc = nlp('Here is some text to encode')"
      ],
      "metadata": {
        "id": "EfP8MxBQWkpT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Category : \n",
        "  NUMBERS = \"NUMBERS\"\n",
        "  LETTERS = \"LETTERS\"\n",
        "\n",
        "letters = ['These are lovely letter values', 'I sent a letter to the post office', 'My GPA is actually decent this year', 'I got an A on my test', \n",
        "           'The letter grade I got was an F', 'Lets sing the alphabet!', 'I got a failing grade', 'I got a passing grade!', 'There are 26 letters in the alphabet',\n",
        "           'I sent an email to my professor']\n",
        "numbers = ['I have a million dollars in the bank', 'I won 1st place in the race', 'I can count from 1-10', 'Elon musk is the richest man in the world',\n",
        "          'I have 16 GB of RAM', 'Can I have your phone number', 'My social security is 123-50-0882', 'I am going to the 10th floor', 'I came in last place',\n",
        "           'I can only spend 50 dollars this week']\n",
        "trainX = []\n",
        "for l in letters:\n",
        "  trainX.append(l);\n",
        "for n in numbers:\n",
        "  trainX.append(n)\n",
        "\n",
        "trainY = [Category.LETTERS, Category.LETTERS, Category.LETTERS, Category.LETTERS, Category.LETTERS, Category.LETTERS, Category.LETTERS, Category.LETTERS, Category.LETTERS, Category.LETTERS,\n",
        "    Category.NUMBERS, Category.NUMBERS, Category.NUMBERS, Category.NUMBERS, Category.NUMBERS, Category.NUMBERS, Category.NUMBERS, Category.NUMBERS, Category.NUMBERS, Category.NUMBERS,]\n",
        "\n",
        "print(trainX)"
      ],
      "metadata": {
        "id": "I1fHAZx_ZOuq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82072bd1-2ba5-4b9a-d1e2-cae88bfe544b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['These are lovely letter values', 'I sent a letter to the post office', 'My GPA is actually decent this year', 'I got an A on my test', 'The letter grade I got was an F', 'Lets sing the alphabet!', 'I got a failing grade', 'I got a passing grade!', 'There are 26 letters in the alphabet', 'I sent an email to my professor', 'I have a million dollars in the bank', 'I won 1st place in the race', 'I can count from 1-10', 'Elon musk is the richest man in the world', 'I have 16 GB of RAM', 'Can I have your phone number', 'My social security is 123-50-0882', 'I am going to the 10th floor', 'I came in last place', 'I can only spend 50 dollars this week']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "docs = [nlp(text) for text in trainX]\n",
        "trainingX = [x.vector for x in docs]"
      ],
      "metadata": {
        "id": "dPWdhcIRaB6I"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Fitting and Prediction\n",
        "\n",
        "This model is 70% accurate using the data we fed it."
      ],
      "metadata": {
        "id": "dqUGZOv5FyjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clfSV = svm.SVC(kernel='linear')\n",
        "clfSV.fit(trainingX, trainY)\n",
        "\n",
        "dummyX = []\n",
        "for l in letters:\n",
        "  dummyX.append(l);\n",
        "for n in numbers:\n",
        "  dummyX.append(n)\n",
        "dummyDocs = [nlp(text) for text in dummyX]\n",
        "dummyXVectors = [x.vector for x in dummyDocs];\n",
        "prediction = clfSVMWordVector.predict(dummyXVectors)\n",
        "\n",
        "print(\"Accuracy of this model is\",  accuracy_score(trainY, prediction) * 100, 'percent accurate')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhS3s9LQ5lQD",
        "outputId": "446928b9-6d3a-4602-d3aa-bf851c9ccef7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of this model is 70.0 percent accurate\n"
          ]
        }
      ]
    }
  ]
}